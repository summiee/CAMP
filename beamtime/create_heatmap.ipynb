{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heatmap radial average vs pp_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import h5py\n",
    "import os\n",
    "import src.pyabel_polar\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hdf_file_name(run_number):\n",
    "    try:\n",
    "        hdf_file_path = '/gpfs/bl1/current/processed/timepix_hdf/'\n",
    "        file_start = \"run_\"+str(run_number).zfill(4)\n",
    "        not_file_end = 'rawOnly.hdf5'\n",
    "        hdf_file = [i for i in os.listdir(hdf_file_path) if os.path.isfile(os.path.join(hdf_file_path,i)) and i.startswith(file_start) and not i.endswith(not_file_end)][0]\n",
    "        hdf_file_complete_path = hdf_file_path+hdf_file\n",
    "        assert os.path.isfile(hdf_file_complete_path), 'File does not exist!'\n",
    "        return hdf_file_complete_path\n",
    "    except IndexError:\n",
    "        print(\"Run\",run_number,\"do not exist!\")\n",
    "\n",
    "def number_of_trains_from_hdf(hdf_file_complete_path):\n",
    "    '''Retrun number of recorded FEL trains in HDF file'''\n",
    "    with h5py.File(hdf_file_complete_path, 'r') as h_file:\n",
    "        trains = len(h_file['tpx3Times/triggerNr'][:])\n",
    "    return trains\n",
    "\n",
    "def data_from_hdf(hdf_file_complete_path, event_type = 'raw'):\n",
    "    '''Read data from TimePix HDF files\n",
    "    Choose raw or centroided data, default is centroided data'''\n",
    "    with h5py.File(hdf_file_complete_path, 'r') as h_file:\n",
    "        tof = h_file[str(event_type)+'/tof'][:]\n",
    "        x_pos = h_file[str(event_type)+'/x'][:]\n",
    "        y_pos = h_file[str(event_type)+'/y'][:]\n",
    "    print('Reading from HDF5 - number of events: {:.2e}'.format(len(tof)))\n",
    "    number_of_trains_from_hdf(hdf_file_complete_path)\n",
    "    return tof, x_pos, y_pos\n",
    "\n",
    "def data_sliced_by_tof(hdf_file_complete_path, tof_start = 0 , tof_end = 0.1, event_type = 'raw'):\n",
    "    '''Slice data with respect to time-of-flight dimension'''\n",
    "    tof, x_pos, y_pos = data_from_hdf(hdf_file_complete_path, event_type)\n",
    "    sliced_x_pos = x_pos[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "    sliced_y_pos = y_pos[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "    sliced_tof = tof[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "#     print('Slicing - number of events: {:.2e} | {:.2%}'.format(len(sliced_tof), len(sliced_tof)/len(tof)))\n",
    "    return sliced_tof, sliced_x_pos, sliced_y_pos\n",
    "\n",
    "def reduce_raw_data(tof, x_pos, y_pos, number_of_events):\n",
    "    '''Reduce data for visualization'''\n",
    "    return tof[:number_of_events], x_pos[:number_of_events],y_pos[:number_of_events]\n",
    "\n",
    "def tof_conversion(tof, time_unit):\n",
    "    '''Convert time axis'''\n",
    "    if time_unit == None:\n",
    "        return tof, 's'\n",
    "    if time_unit == 'milli':\n",
    "        return tof*10**3, 'ms'\n",
    "    if time_unit == 'micro':\n",
    "        return tof*10**6, 'us'\n",
    "\n",
    "def plot_tof(tof, hist_bins=100, time_unit = None):     \n",
    "    '''Plot time-of-flight spectrum via histogram'''\n",
    "    fig = plt.subplots(num = 1)\n",
    "    plt.clf()\n",
    "    tof, time_tof_unit = tof_conversion(tof, time_unit)\n",
    "    plt.hist(tof, bins = hist_bins)\n",
    "    plt.title('histogram: time-of-flight')\n",
    "    plt.xlabel('ToF [{}]'.format(time_tof_unit))\n",
    "    plt.ylabel('number of events')\n",
    "    plt.show()\n",
    "    \n",
    "def vmi_image(x_pos, y_pos, show_image = True):\n",
    "    '''Display VMI image - cmax empirically found to surpress hot pixel '''\n",
    "    fig = plt.figure(num = 6)\n",
    "    plt.clf()\n",
    "    counts, xbins, ybins, image = plt.hist2d(x_pos, y_pos,bins=np.linspace(0, 256, 257)) #, cmax= 1000)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x_pos [px]')\n",
    "    plt.ylabel('y_pos [px]')\n",
    "    if show_image == False:\n",
    "        plt.close()\n",
    "    return counts\n",
    "    \n",
    "def display_tof_and_vmi_of_tof_interval(hdf_file_complete_path, tof_start = 0 , tof_end = 0.1, hist_bins = 100, time_unit = None, event_type = 'raw'):\n",
    "    '''Display VMI Image and time-of-flight spetrum'''\n",
    "    tof, x_pos, y_pos = data_sliced_by_tof(hdf_file_complete_path, tof_start, tof_end, event_type)\n",
    "    plot_tof(tof, hist_bins, time_unit)\n",
    "    vmi_image(x_pos,y_pos)\n",
    "\n",
    "    \n",
    "def transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius, non_plot = False):\n",
    "    \n",
    "    counts = vmi_image(x_pos, y_pos, show_image = False)\n",
    "    image_cart = np.flipud(counts.transpose())\n",
    "    \n",
    "    image_polar, r_grid, theta_grid = src.pyabel_polar.reproject_image_into_polar(image_cart, origin=(x_center,y_center))\n",
    "    radial_ave = np.sum(image_polar, axis=1)\n",
    "    \n",
    "    if non_plot == False:\n",
    "        fig = plt.figure(figsize = (10,10),num = 6)\n",
    "        plt.clf()\n",
    "        plt.imshow(image_cart)\n",
    "        plt.scatter(x_center, y_center, color='r')\n",
    "        plt.gcf().gca().add_artist(plt.Circle((x_center, y_center), radius, color='r', fill=False))\n",
    "        plt.xlabel('x_posr [px]')\n",
    "        plt.ylabel('y_posr [px]')\n",
    "        plt.title('VMI image')\n",
    "\n",
    "    #     fig = plt.figure(num = 7)\n",
    "    #     plt.clf()\n",
    "    #     plt.imshow(image_polar)\n",
    "    #     plt.title('Image - polar coordinates')\n",
    "\n",
    "        fig = plt.figure(num = 8)\n",
    "        plt.clf()\n",
    "        plt.plot(radial_ave,'r-')\n",
    "        plt.title('Radial average')\n",
    "        plt.xlabel('r [px]')\n",
    "        plt.ylabel('counts')\n",
    "        plt.show()\n",
    "    \n",
    "    return radial_ave\n",
    "\n",
    "def get_delay_stage_pos_from_txt_file(run_interval):\n",
    "    runs = []\n",
    "    delay_pos = []\n",
    "    filepath = '/home/bl1user/Desktop/erk20919/CAMP/beamtime/run_pp-delay.txt'\n",
    "    with open(filepath) as fp:\n",
    "        for cnt, line in enumerate(fp):\n",
    "            tt = [x.strip() for x in line.split(',')]\n",
    "            runs.append(int(tt[0]))\n",
    "            delay_pos.append(float(tt[1]))\n",
    "    runs = runs[runs.index(run_interval[0]):runs.index(run_interval[1])+1]\n",
    "    delay_pos = delay_pos[runs.index(run_interval[0]):runs.index(run_interval[1])+1]\n",
    "    return runs, delay_pos\n",
    "\n",
    "def save_all_delay_for_fragment(file_prefix, fragment ,run_interval, tof_start,tof_end, x_center, y_center, radius):\n",
    "    runs_file , delay_stage = get_delay_stage_pos_from_txt_file(run_interval)\n",
    "    print(type(delay_stage))\n",
    "\n",
    "    for i in range(run_interval[0], run_interval[1]+1):\n",
    "        print(delay_stage[i-run_interval[0]])\n",
    "        hdf_file = generate_hdf_file_name(i)\n",
    "        tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end, event_type = \"raw\")\n",
    "        radial_average = transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius, non_plot = True) \n",
    "        number_of_trains = number_of_trains_from_hdf(hdf_file)\n",
    "        \n",
    "        save_to_path = 'intermediate_data/'\n",
    "        save_file_name = str(file_prefix)+\"_\"+str(fragment)+\"_\"+str(delay_stage[i-run_interval[0]])\n",
    "        np.savez(save_to_path+save_file_name, radial_average=radial_average, fragment= fragment, delay_stage = delay_stage[i-run_interval[0]], number_of_trains = number_of_trains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define source file & describe measurment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 88 \n",
    "\n",
    "hdf_file = generate_hdf_file_name(run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete time-of-flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from HDF5 - number of events: 4.59e+07\n"
     ]
    }
   ],
   "source": [
    "tof_start = 0E-6\n",
    "tof_end = 12E-6\n",
    "tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end)\n",
    "\n",
    "plot_tof(tof, hist_bins = 500, time_unit = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice time-of-flight dimension and create VMI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from HDF5 - number of events: 4.59e+07\n"
     ]
    }
   ],
   "source": [
    "# I2+ \n",
    "# tof_start, tof_end = 7.60E-6, 8.01E-6\n",
    "\n",
    "# I3+ \n",
    "# tof_start, tof_end = 6.4E-6, 6.7E-6\n",
    "\n",
    "# I4+ \n",
    "# tof_start, tof_end = 5.75E-6, 5.95E-6\n",
    "\n",
    "# I5+ \n",
    "# tof_start, tof_end = 5.2E-6, 5.4E-6\n",
    "\n",
    "# I6+ \n",
    "tof_start, tof_end = 4.85E-6, 5.02E-6\n",
    "\n",
    "display_tof_and_vmi_of_tof_interval(hdf_file, tof_start, tof_end, event_type = 'raw',time_unit = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose center and calc radial average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from HDF5 - number of events: 4.59e+07\n"
     ]
    }
   ],
   "source": [
    "tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end, event_type=\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fragment = 'I2+'\n",
    "# x_center, y_center = 134, 118        \n",
    "# radius = 80\n",
    "\n",
    "# fragment = 'I3+'       #  -> no clear peak \n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "# fragment = 'I4+'\n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "# fragment = 'I5+'\n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "fragment = 'I6+'\n",
    "x_center, y_center = 131, 120        \n",
    "radius = 30\n",
    "\n",
    "radial_average = transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to intermediate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = '400nm_delay'\n",
    "run_interval = [88, 129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "61.0\n",
      "Reading from HDF5 - number of events: 4.59e+07\n",
      "63.0\n",
      "Reading from HDF5 - number of events: 5.14e+07\n",
      "62.0\n",
      "Reading from HDF5 - number of events: 4.72e+07\n",
      "63.5\n",
      "Reading from HDF5 - number of events: 5.18e+07\n",
      "61.5\n",
      "Reading from HDF5 - number of events: 4.67e+07\n",
      "61.9\n",
      "Reading from HDF5 - number of events: 4.86e+07\n",
      "61.1\n",
      "Reading from HDF5 - number of events: 4.84e+07\n",
      "64.0\n",
      "Reading from HDF5 - number of events: 5.83e+07\n",
      "62.7\n",
      "Reading from HDF5 - number of events: 4.46e+07\n",
      "63.2\n",
      "Reading from HDF5 - number of events: 5.25e+07\n",
      "62.1\n",
      "Reading from HDF5 - number of events: 4.98e+07\n",
      "63.1\n",
      "Reading from HDF5 - number of events: 5.49e+07\n",
      "62.2\n",
      "Reading from HDF5 - number of events: 3.94e+07\n",
      "62.9\n",
      "Reading from HDF5 - number of events: 5.08e+07\n",
      "62.3\n",
      "Reading from HDF5 - number of events: 5.01e+07\n",
      "62.95\n",
      "Reading from HDF5 - number of events: 5.34e+07\n",
      "62.4\n",
      "Reading from HDF5 - number of events: 5.00e+07\n",
      "62.75\n",
      "Reading from HDF5 - number of events: 5.01e+07\n",
      "62.5\n",
      "Reading from HDF5 - number of events: 5.23e+07\n",
      "62.85\n",
      "Reading from HDF5 - number of events: 5.05e+07\n",
      "62.6\n",
      "Reading from HDF5 - number of events: 5.06e+07\n",
      "62.8\n",
      "Reading from HDF5 - number of events: 4.91e+07\n",
      "65.0\n",
      "Reading from HDF5 - number of events: 6.18e+07\n",
      "62.83\n",
      "Reading from HDF5 - number of events: 4.97e+07\n",
      "63.4\n",
      "Reading from HDF5 - number of events: 5.21e+07\n",
      "60.0\n",
      "Reading from HDF5 - number of events: 4.73e+07\n",
      "63.6\n",
      "Reading from HDF5 - number of events: 5.02e+07\n",
      "59.0\n",
      "Reading from HDF5 - number of events: 2.49e+07\n",
      "59.0\n",
      "Reading from HDF5 - number of events: 4.72e+07\n",
      "61.9\n",
      "Reading from HDF5 - number of events: 4.60e+07\n",
      "62.1\n",
      "Reading from HDF5 - number of events: 4.64e+07\n",
      "62.8\n",
      "Reading from HDF5 - number of events: 4.89e+07\n",
      "58.0\n",
      "Reading from HDF5 - number of events: 8.80e+06\n",
      "58.0\n",
      "Reading from HDF5 - number of events: 4.55e+07\n",
      "64.0\n",
      "Reading from HDF5 - number of events: 8.79e+06\n",
      "60.0\n",
      "Reading from HDF5 - number of events: 2.83e+07\n",
      "58.0\n",
      "Reading from HDF5 - number of events: 4.42e+07\n",
      "64.0\n",
      "Reading from HDF5 - number of events: 4.73e+07\n",
      "60.0\n",
      "Reading from HDF5 - number of events: 4.29e+07\n",
      "62.5\n",
      "Reading from HDF5 - number of events: 4.68e+07\n",
      "59.0\n",
      "Reading from HDF5 - number of events: 4.52e+07\n",
      "62.0\n",
      "Reading from HDF5 - number of events: 4.85e+07\n"
     ]
    }
   ],
   "source": [
    "save_all_delay_for_fragment(file_prefix, fragment ,run_interval, tof_start, tof_end, x_center, y_center, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_plots(radial_averages_norm, delay_stage_pos, fragment):\n",
    "    \n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(radial_averages_norm)))\n",
    "    print(colors.shape)\n",
    "    print(colors[0])\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,10),num = 10)\n",
    "    for i in range(len(radial_averages_norm)):\n",
    "        plt.plot(radial_averages_norm[i],label=delay_stage_pos[i], color = colors[i])\n",
    "    plt.xlabel('r')\n",
    "    plt.ylabel('counts')\n",
    "    plt.legend()\n",
    "    plt.title(str(fragment))\n",
    "    \n",
    "def heatmap(radial_averages_norm, fragment):\n",
    "    fig = plt.figure(figsize = (10,10),num = 11)\n",
    "    image = np.column_stack(radial_averages_norm)\n",
    "    plt.imshow(image, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.xticks(np.arange(len(delay_stage_pos)), delay_stage_pos)\n",
    "    print('Number of delay steps:',len(delay_stage_pos))\n",
    "    plt.title(str(fragment))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def load_radial_data(file_prefix,fragment):\n",
    "    \n",
    "    load_from_path = 'intermediate_data/'\n",
    "    files = [i for i in os.listdir(load_from_path) if os.path.isfile(os.path.join(load_from_path,i)) and str(file_prefix)+\"_\"+str(fragment) in i]\n",
    "    \n",
    "    radial_averages =[]\n",
    "    delay_stage_pos = []\n",
    "    norm_counts = []\n",
    "    \n",
    "    for i in files:\n",
    "        npzfile = np.load(load_from_path+i)\n",
    "        radial_averages.append(npzfile['radial_average'])\n",
    "        delay_stage_pos.append(float(npzfile['delay_stage']))\n",
    "        fragment = (npzfile['fragment'])\n",
    "        norm_counts.append(float(npzfile['number_of_trains']))\n",
    "        \n",
    "    radial_averages = np.array(radial_averages)\n",
    "    delay_stage_pos = np.array(delay_stage_pos)\n",
    "    norm_counts = np.array(norm_counts)\n",
    "\n",
    "    sort_ind = np.argsort(delay_stage_pos)\n",
    "    radial_averages = radial_averages[sort_ind]\n",
    "    norm_counts = norm_counts[sort_ind]\n",
    "    delay_stage_pos = delay_stage_pos[sort_ind]\n",
    "    \n",
    "    radial_averages_norm = []\n",
    "    for i in range(len(radial_averages)):\n",
    "        radial_averages_norm.append(radial_averages[i]/norm_counts[i])\n",
    "    radial_averages_norm = np.array(radial_averages_norm)\n",
    "\n",
    "    print('fragment:',fragment) \n",
    "    print('number of delay_stage_pos:',len(delay_stage_pos))\n",
    "    print('delay_stage_steps:',delay_stage_pos)\n",
    "\n",
    "    return radial_averages_norm, delay_stage_pos     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment: I6+\n",
      "number of delay_stage_pos: 29\n",
      "delay_stage_steps: [58.   59.   60.   61.   61.1  61.5  61.9  62.   62.1  62.2  62.3  62.4\n",
      " 62.5  62.6  62.7  62.75 62.8  62.83 62.85 62.9  62.95 63.   63.1  63.2\n",
      " 63.4  63.5  63.6  64.   65.  ]\n"
     ]
    }
   ],
   "source": [
    "file_prefix = '400nm_delay'\n",
    "fragment = 'I6+'\n",
    "\n",
    "radial_averages_norm, delay_stage_pos = load_radial_data(file_prefix,fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 4)\n",
      "[0.5 0.  1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "simple_plots(radial_averages_norm, delay_stage_pos, fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of delay steps: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bl1user/.conda/envs/CAMP/lib/python3.7/site-packages/ipykernel/eventloops.py:106: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "  app.exec_()\n",
      "/home/bl1user/.conda/envs/CAMP/lib/python3.7/site-packages/ipykernel/eventloops.py:106: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "  app.exec_()\n",
      "/home/bl1user/.conda/envs/CAMP/lib/python3.7/site-packages/ipykernel/eventloops.py:106: UserWarning: Attempting to set identical bottom == top == 100.0 results in singular transformations; automatically expanding.\n",
      "  app.exec_()\n",
      "/home/bl1user/.conda/envs/CAMP/lib/python3.7/site-packages/matplotlib/ticker.py:2588: RuntimeWarning: invalid value encountered in log10\n",
      "  vmin = np.log10(vmin / (1 - vmin))\n",
      "/home/bl1user/.conda/envs/CAMP/lib/python3.7/site-packages/matplotlib/ticker.py:2589: RuntimeWarning: invalid value encountered in log10\n",
      "  vmax = np.log10(vmax / (1 - vmax))\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    }
   ],
   "source": [
    "heatmap(radial_averages_norm, fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
