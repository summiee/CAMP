{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heatmap radial average vs pp_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import h5py\n",
    "import os\n",
    "import src.pyabel_polar\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hdf_file_name(run_number):\n",
    "    try:\n",
    "        hdf_file_path = '/gpfs/bl1/current/processed/timepix_hdf/'\n",
    "        file_start = \"run_\"+str(run_number).zfill(4)\n",
    "        not_file_end = 'rawOnly.hdf5'\n",
    "        hdf_file = [i for i in os.listdir(hdf_file_path) if os.path.isfile(os.path.join(hdf_file_path,i)) and i.startswith(file_start) and not i.endswith(not_file_end)][0]\n",
    "        hdf_file_complete_path = hdf_file_path+hdf_file\n",
    "        assert os.path.isfile(hdf_file_complete_path), 'File does not exist!'\n",
    "        return hdf_file_complete_path\n",
    "    except IndexError:\n",
    "        print(\"Run\",run_number,\"do not exist!\")\n",
    "\n",
    "def number_of_trains_from_hdf(hdf_file_complete_path):\n",
    "    '''Retrun number of recorded FEL trains in HDF file'''\n",
    "    with h5py.File(hdf_file_complete_path, 'r') as h_file:\n",
    "        trains = len(h_file['tpx3Times/triggerNr'][:])\n",
    "    return trains\n",
    "\n",
    "def data_from_hdf(hdf_file_complete_path, event_type = 'raw'):\n",
    "    '''Read data from TimePix HDF files\n",
    "    Choose raw or centroided data, default is centroided data'''\n",
    "    with h5py.File(hdf_file_complete_path, 'r') as h_file:\n",
    "        tof = h_file[str(event_type)+'/tof'][:]\n",
    "        x_pos = h_file[str(event_type)+'/x'][:]\n",
    "        y_pos = h_file[str(event_type)+'/y'][:]\n",
    "    print('Reading from {} - number of events: {:.2e}'.format(hdf_file_complete_path, len(tof)))\n",
    "    number_of_trains_from_hdf(hdf_file_complete_path)\n",
    "    return tof, x_pos, y_pos\n",
    "\n",
    "def data_sliced_by_tof(hdf_file_complete_path, tof_start = 0 , tof_end = 0.1, event_type = 'raw'):\n",
    "    '''Slice data with respect to time-of-flight dimension'''\n",
    "    tof, x_pos, y_pos = data_from_hdf(hdf_file_complete_path, event_type)\n",
    "    sliced_x_pos = x_pos[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "    sliced_y_pos = y_pos[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "    sliced_tof = tof[np.logical_and(tof > tof_start, tof < tof_end)]\n",
    "#     print('Slicing - number of events: {:.2e} | {:.2%}'.format(len(sliced_tof), len(sliced_tof)/len(tof)))\n",
    "    return sliced_tof, sliced_x_pos, sliced_y_pos\n",
    "\n",
    "def reduce_raw_data(tof, x_pos, y_pos, number_of_events):\n",
    "    '''Reduce data for visualization'''\n",
    "    return tof[:number_of_events], x_pos[:number_of_events],y_pos[:number_of_events]\n",
    "\n",
    "def tof_conversion(tof, time_unit):\n",
    "    '''Convert time axis'''\n",
    "    if time_unit == None:\n",
    "        return tof, 's'\n",
    "    if time_unit == 'milli':\n",
    "        return tof*10**3, 'ms'\n",
    "    if time_unit == 'micro':\n",
    "        return tof*10**6, 'us'\n",
    "\n",
    "def plot_tof(tof, hist_bins=100, time_unit = None):     \n",
    "    '''Plot time-of-flight spectrum via histogram'''\n",
    "    fig = plt.subplots(num = 1)\n",
    "    plt.clf()\n",
    "    tof, time_tof_unit = tof_conversion(tof, time_unit)\n",
    "    plt.hist(tof, bins = hist_bins)\n",
    "    plt.title('histogram: time-of-flight')\n",
    "    plt.xlabel('ToF [{}]'.format(time_tof_unit))\n",
    "    plt.ylabel('number of events')\n",
    "    plt.show()\n",
    "    \n",
    "def vmi_image(x_pos, y_pos, show_image = True):\n",
    "    '''Display VMI image - cmax empirically found to surpress hot pixel '''\n",
    "    fig = plt.figure(num = 6)\n",
    "    plt.clf()\n",
    "    counts, xbins, ybins, image = plt.hist2d(x_pos, y_pos,bins=np.linspace(0, 256, 257)) #, cmax= 1000)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x_pos [px]')\n",
    "    plt.ylabel('y_pos [px]')\n",
    "    if show_image == False:\n",
    "        plt.close()\n",
    "    return counts\n",
    "    \n",
    "def display_tof_and_vmi_of_tof_interval(hdf_file_complete_path, tof_start = 0 , tof_end = 0.1, hist_bins = 100, time_unit = None, event_type = 'raw'):\n",
    "    '''Display VMI Image and time-of-flight spetrum'''\n",
    "    tof, x_pos, y_pos = data_sliced_by_tof(hdf_file_complete_path, tof_start, tof_end, event_type)\n",
    "    plot_tof(tof, hist_bins, time_unit)\n",
    "    vmi_image(x_pos,y_pos)\n",
    "\n",
    "    \n",
    "def transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius, non_plot = False):\n",
    "    \n",
    "    counts = vmi_image(x_pos, y_pos, show_image = False)\n",
    "    image_cart = np.flipud(counts.transpose())\n",
    "    \n",
    "    image_polar, r_grid, theta_grid = src.pyabel_polar.reproject_image_into_polar(image_cart, origin=(x_center,y_center))\n",
    "    radial_ave = np.sum(image_polar, axis=1)\n",
    "    \n",
    "    if non_plot == False:\n",
    "        fig = plt.figure(figsize = (10,10),num = 6)\n",
    "        plt.clf()\n",
    "        plt.imshow(image_cart)\n",
    "        plt.scatter(x_center, y_center, color='r')\n",
    "        plt.gcf().gca().add_artist(plt.Circle((x_center, y_center), radius, color='r', fill=False))\n",
    "        plt.xlabel('x_posr [px]')\n",
    "        plt.ylabel('y_posr [px]')\n",
    "        plt.title('VMI image')\n",
    "\n",
    "    #     fig = plt.figure(num = 7)\n",
    "    #     plt.clf()\n",
    "    #     plt.imshow(image_polar)\n",
    "    #     plt.title('Image - polar coordinates')\n",
    "\n",
    "        fig = plt.figure(num = 8)\n",
    "        plt.clf()\n",
    "        plt.plot(radial_ave,'r-')\n",
    "        plt.title('Radial average')\n",
    "        plt.xlabel('r [px]')\n",
    "        plt.ylabel('counts')\n",
    "        plt.show()\n",
    "    \n",
    "    return radial_ave\n",
    "\n",
    "def get_delay_stage_pos_from_txt_file(run_interval):\n",
    "    runs = []\n",
    "    delay_pos = []\n",
    "    filepath = '/home/bl1user/Desktop/erk20919/CAMP/beamtime/run_pp-delay.txt'\n",
    "    with open(filepath) as fp:\n",
    "        for cnt, line in enumerate(fp):\n",
    "            tt = [x.strip() for x in line.split(',')]\n",
    "            runs.append(int(tt[0]))\n",
    "            delay_pos.append(float(tt[1]))\n",
    "    delay_pos = delay_pos[runs.index(run_interval[0]):runs.index(run_interval[1])+1]\n",
    "    runs = runs[runs.index(run_interval[0]):runs.index(run_interval[1])+1]\n",
    "    return runs, delay_pos\n",
    "\n",
    "def save_all_delay_for_fragment(file_prefix, fragment ,run_interval, tof_start,tof_end, x_center, y_center, radius, timepix_event_type):\n",
    "    runs_file , delay_stage = get_delay_stage_pos_from_txt_file(run_interval)\n",
    "    for i in range(run_interval[0], run_interval[1]+1):\n",
    "        print(delay_stage[i-run_interval[0]])\n",
    "        hdf_file = generate_hdf_file_name(i)\n",
    "        tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end, event_type = timepix_event_type)\n",
    "        radial_average = transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius, non_plot = True) \n",
    "        number_of_trains = number_of_trains_from_hdf(hdf_file)\n",
    "        \n",
    "        save_to_path = 'intermediate_data/'\n",
    "        save_file_name = str(file_prefix)+\"_\"+str(fragment)+\"_\"+str(delay_stage[i-run_interval[0]])\n",
    "        np.savez(save_to_path+save_file_name, radial_average=radial_average, fragment= fragment, delay_stage = delay_stage[i-run_interval[0]], number_of_trains = number_of_trains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define source file & describe measurment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = 185\n",
    "timepix_event_type = 'raw'\n",
    "\n",
    "hdf_file = generate_hdf_file_name(run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete time-of-flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from /gpfs/bl1/current/processed/timepix_hdf/run_0185_20191213-1441.hdf5 - number of events: 4.43e+07\n"
     ]
    }
   ],
   "source": [
    "tof_start = 0E-6\n",
    "tof_end = 12E-6\n",
    "tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end, event_type = timepix_event_type)\n",
    "\n",
    "plot_tof(tof, hist_bins = 500, time_unit = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice time-of-flight dimension and create VMI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from /gpfs/bl1/current/processed/timepix_hdf/run_0185_20191213-1441.hdf5 - number of events: 4.43e+07\n"
     ]
    }
   ],
   "source": [
    "# I2+ \n",
    "# tof_start, tof_end = 7.60E-6, 8.01E-6\n",
    "\n",
    "# I3+ \n",
    "# tof_start, tof_end = 6.4E-6, 6.7E-6\n",
    "\n",
    "# I4+ \n",
    "# tof_start, tof_end = 5.75E-6, 5.95E-6\n",
    "\n",
    "# I5+ \n",
    "# tof_start, tof_end = 5.2E-6, 5.4E-6\n",
    "\n",
    "# I6+ \n",
    "tof_start, tof_end = 4.85E-6, 5.02E-6\n",
    "\n",
    "display_tof_and_vmi_of_tof_interval(hdf_file, tof_start, tof_end, event_type = timepix_event_type, time_unit = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose center and calc radial average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from /gpfs/bl1/current/processed/timepix_hdf/run_0185_20191213-1441.hdf5 - number of events: 4.43e+07\n"
     ]
    }
   ],
   "source": [
    "tof, x_pos, y_pos = data_sliced_by_tof(hdf_file, tof_start , tof_end, event_type = timepix_event_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fragment = 'I2+'\n",
    "# x_center, y_center = 134, 118        \n",
    "# radius = 80\n",
    "\n",
    "# fragment = 'I3+'       #  -> no clear peak \n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "# fragment = 'I4+'\n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "# fragment = 'I5+'\n",
    "# x_center, y_center = 131, 127          \n",
    "# radius = 18\n",
    "\n",
    "fragment = 'I6+'\n",
    "x_center, y_center = 133, 119        \n",
    "radius = 35\n",
    "\n",
    "radial_average = transform_vmi_to_polar(x_pos, y_pos, x_center, y_center, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to intermediate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = '800nm_delay'\n",
    "run_interval = [208, 209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320.0\n",
      "Reading from /gpfs/bl1/current/processed/timepix_hdf/run_0208_20191213-1901.hdf5 - number of events: 4.98e+07\n",
      "0.0\n",
      "Reading from /gpfs/bl1/current/processed/timepix_hdf/run_0209_20191213-1913.hdf5 - number of events: 1.81e+07\n"
     ]
    }
   ],
   "source": [
    "save_all_delay_for_fragment(file_prefix, fragment ,run_interval, tof_start, tof_end, x_center, y_center, radius, timepix_event_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_plots(radial_averages_norm, delay_stage_pos, fragment):\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(radial_averages_norm)))\n",
    "    fig = plt.figure(figsize = (10,10),num = 10)\n",
    "    for i in range(len(radial_averages_norm)):\n",
    "        plt.plot(radial_averages_norm[i],label=delay_stage_pos[i], color = colors[i])\n",
    "    plt.xlabel('r')\n",
    "    plt.ylabel('counts')\n",
    "    plt.legend()\n",
    "    plt.title(str(fragment), fontsize = 20)\n",
    "    print('Number of delay steps:',len(delay_stage_pos))\n",
    "    plt.show()\n",
    "    \n",
    "def heatmap(radial_averages_norm, fragment):\n",
    "    fig = plt.figure(figsize = (10,10),num = 11)\n",
    "    image = np.column_stack(radial_averages_norm)\n",
    "    plt.imshow(image, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.xticks(np.arange(len(delay_stage_pos)), delay_stage_pos)\n",
    "    plt.title(str(fragment), fontsize = 20)\n",
    "    print('Number of delay steps:',len(delay_stage_pos))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def load_radial_data(file_prefix,fragment):\n",
    "    \n",
    "    load_from_path = 'intermediate_data/'\n",
    "    files = [i for i in os.listdir(load_from_path) if os.path.isfile(os.path.join(load_from_path,i)) and str(file_prefix)+\"_\"+str(fragment) in i]\n",
    "    \n",
    "    radial_averages =[]\n",
    "    delay_stage_pos = []\n",
    "    norm_counts = []\n",
    "    \n",
    "    for i in files:\n",
    "        npzfile = np.load(load_from_path+i)\n",
    "        radial_averages.append(npzfile['radial_average'])\n",
    "        delay_stage_pos.append(float(npzfile['delay_stage']))\n",
    "        fragment = (npzfile['fragment'])\n",
    "        norm_counts.append(float(npzfile['number_of_trains']))\n",
    "        \n",
    "    radial_averages = np.array(radial_averages)\n",
    "    delay_stage_pos = np.array(delay_stage_pos)\n",
    "    norm_counts = np.array(norm_counts)\n",
    "\n",
    "    sort_ind = np.argsort(delay_stage_pos)\n",
    "    radial_averages = radial_averages[sort_ind]\n",
    "    norm_counts = norm_counts[sort_ind]\n",
    "    delay_stage_pos = delay_stage_pos[sort_ind]\n",
    "    \n",
    "    radial_averages_norm = []\n",
    "    for i in range(len(radial_averages)):\n",
    "        radial_averages_norm.append(radial_averages[i]/norm_counts[i])\n",
    "    radial_averages_norm = np.array(radial_averages_norm)\n",
    "\n",
    "    print('fragment:',fragment) \n",
    "    print('number of delay_stage_pos:',len(delay_stage_pos))\n",
    "    print('delay_stage_steps:',delay_stage_pos)\n",
    "\n",
    "    return radial_averages_norm, delay_stage_pos     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment: I6+\n",
      "number of delay_stage_pos: 24\n",
      "delay_stage_steps: [  0.   320.   330.   335.   340.   341.   342.   343.   344.   344.25\n",
      " 344.5  344.75 345.   345.25 345.5  345.75 345.82 346.   346.25 346.5\n",
      " 346.75 347.   347.5  348.  ]\n"
     ]
    }
   ],
   "source": [
    "file_prefix = '800nm_delay'\n",
    "fragment = 'I6+'\n",
    "\n",
    "radial_averages_norm, delay_stage_pos = load_radial_data(file_prefix,fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of delay steps: 22\n"
     ]
    }
   ],
   "source": [
    "simple_plots(radial_averages_norm, delay_stage_pos, fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of delay steps: 24\n"
     ]
    }
   ],
   "source": [
    "heatmap(radial_averages_norm, fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
